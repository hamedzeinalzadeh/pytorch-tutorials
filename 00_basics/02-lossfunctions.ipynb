{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "115e95f7-a4d9-4ea3-b867-83bfe4d244b2",
   "metadata": {},
   "source": [
    "# Loss Functions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "641e83f8-7564-44c2-a1f5-73a4481ebecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e8822e-7694-4e6b-abb6-7f2a359670e4",
   "metadata": {},
   "source": [
    "## MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61eb1de2-e43a-48d5-bbd4-f0e76e429fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = torch.randn(4, 5)\n",
    "label = torch.randn(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17c3fdc0-8760-43d5-baf1-e03b8a9e21e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse = nn.MSELoss(reductoin=mean), reduction = 'none', 'mean'(default), 'sum'\n",
    "mse = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e00d43e-2793-49bb-bf9a-910743b54f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2132)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = mse(prediction, label)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "763d29c0-4807-4879-9b65-c0a4ce3bacc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2132)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement from scratch\n",
    "((prediction - label) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45ebe91-236b-476a-98ac-7e4e3522e5c2",
   "metadata": {},
   "source": [
    "## Binary Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "960fe84d-3795-469b-9308-cbe31ed15882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6475,  0.3130, -0.6018, -1.1645,  0.6064],\n",
       "        [-0.9969, -0.3796, -0.5490, -0.9377, -0.0159],\n",
       "        [-0.3647,  1.4951,  1.5219, -0.5675,  0.0842],\n",
       "        [ 0.2892, -2.3569, -0.3242,  0.6555, -0.5519]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a235be68-ab62-4ee7-9947-3c64f0273e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 1., 1.],\n",
       "        [0., 1., 0., 1., 0.],\n",
       "        [1., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create label wiht the same size as prediction filled with 0 or 1 values\n",
    "label = torch.empty_like(prediction).random_(0, 2)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fce14ced-6dcb-4975-9bb7-e9fd59f66bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_ = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c9c4f36-92c5-48ed-b73b-cd11c7b7dd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "983fec9b-9778-4631-8e1e-350962db4939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9104)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = bce(sigmoid_(prediction), label)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f59e300-9d1b-41f1-8785-1111fab074b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9104)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BCE with logits loss(automatically feed the level before the end to sigomid)\n",
    "bce_logits = nn.BCEWithLogitsLoss()\n",
    "loss = bce_logits(prediction, label)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6b717f6-3dbf-4883-a001-b60b6fa7779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement with numpy from scratch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "869abd64-1ad5-4bd0-ac79-56a68caa7363",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = prediction.numpy()\n",
    "y = label.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "11de38d2-c92f-47ba-883c-17874efcaf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The inputs of BCE Loss might be between 0 and 1\n",
    "def sigmoid_converter(x):\n",
    "    return 1 / (1 + np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "41f1e7cd-763c-40f9-bca7-10130c7e179f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = sigmoid_converter(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec6a1443-c749-44a4-a27e-132a57382857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6877740432487289"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_values = []\n",
    "for i, j in zip(y.flatten(), y_hat.flatten()):\n",
    "    loss_values.append(-np.log(j) if i == 1 else -np.log(1 - j))\n",
    "\n",
    "np.mean(loss_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2ab110-cf3a-4a84-9ac1-941e6cd19ce5",
   "metadata": {},
   "source": [
    "## Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "72409c41-2b08-436a-a9a4-326a2e01629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b7b63830-9c79-48bc-a115-3ea7c7c891af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption: 3 samples, 5 features\n",
    "input_ = torch.randn(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "55d5c2bc-4e04-48f6-acd5-f2ff928fcc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "target = torch.empty(3).random_(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e31675-8bee-4bfc-b65d-2bc31ca7fddf",
   "metadata": {},
   "source": [
    "**NOTE**:\n",
    "\n",
    "The target should be **ONE DIMENSIONAL** with the limitation of `(0, num_of_classes - 1)`\n",
    "\n",
    "Pytorch convert it to a **one_hot encoded** tensor automatically in its calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "81e61c45-87b6-48de-aa6e-1b9107c50e20",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Long but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ce_loss(input_, target)\n",
      "File \u001b[0;32m~/miniconda3/envs/data/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/data/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/data/lib/python3.12/site-packages/torch/nn/modules/loss.py:1293\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mcross_entropy(\n\u001b[1;32m   1294\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1295\u001b[0m         target,\n\u001b[1;32m   1296\u001b[0m         weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[1;32m   1297\u001b[0m         ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index,\n\u001b[1;32m   1298\u001b[0m         reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction,\n\u001b[1;32m   1299\u001b[0m         label_smoothing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_smoothing,\n\u001b[1;32m   1300\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/data/lib/python3.12/site-packages/torch/nn/functional.py:3479\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3478\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mcross_entropy_loss(\n\u001b[1;32m   3480\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   3481\u001b[0m     target,\n\u001b[1;32m   3482\u001b[0m     weight,\n\u001b[1;32m   3483\u001b[0m     _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction),\n\u001b[1;32m   3484\u001b[0m     ignore_index,\n\u001b[1;32m   3485\u001b[0m     label_smoothing,\n\u001b[1;32m   3486\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
     ]
    }
   ],
   "source": [
    "ce_loss(input_, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77cc172-5541-4b8b-8431-172289601a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
